{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example in Computer Vision\n",
    "\n",
    "We will build a model on the MNIST dataset to recognize hand-written digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n",
      "0.6.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "%matplotlib inline\n",
    "\n",
    "print (torch.__version__)\n",
    "print (torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test data, will automatically download\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='mnist', train=True, \n",
    "                    transform=transform, download=True)\n",
    "test_data = torchvision.datasets.MNIST(root='mnist', train=False,\n",
    "                    transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# dataset statistics\n",
    "print (len(train_data))\n",
    "print (len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images in MNIST show hand-writtern digits, the task is to recognize the digit. Let's first see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x103192630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, lab = train_data[0]\n",
    "print (\"Label:\", lab)\n",
    "\n",
    "img = img.reshape(28, 28)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the example above, the image shows '5', and the corresponding label is 5. \n",
    "\n",
    "Next, we write a model class to perform the task. Note that I'm using a very naive model structure, you can feel free to change the model structure and see if you can get better performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # conv2d parameters: in_channels, out_channels, kernel_size, stride\n",
    "        # input shape: (bsz, 1, 28, 28)\n",
    "        self.conv = nn.Conv2d(in_channels=1, \n",
    "                              out_channels=32, \n",
    "                              kernel_size=3, \n",
    "                              stride=1, \n",
    "                              padding=1) \n",
    "        # output shape: (bsz, 32, 28, 28)\n",
    "        self.dropout1 = nn.Dropout2d(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # output shape: (bsz, 32, 14, 14)\n",
    "        self.fc1 = nn.Linear(6272, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x) #(bsz, 1, 28, 28) -> (bsz, 32, 28, 28)\n",
    "        x = self.relu(x) \n",
    "        x = self.pool(x) #-> (bsz, 32, 14, 14)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1) #->(bsz, 6272)\n",
    "        x = self.fc1(x) #->(bsz, 128)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x) #->(bsz, 10) ##raw logits\n",
    "        return x   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our training function\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 200 == 0:\n",
    "            print ('Train Epoch: {}, Batch Index: {}, Loss: {}'.format(\n",
    "                epoch, batch_idx, loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define out testing function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1,) #(bsz,)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    print (\" Test Accuracy: {}%\".format(\n",
    "            correct/len(test_loader.dataset)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Batch Index: 0, Loss: 2.305495023727417\n",
      "Train Epoch: 1, Batch Index: 200, Loss: 0.3825370669364929\n",
      "Train Epoch: 1, Batch Index: 400, Loss: 0.3247998356819153\n",
      "Train Epoch: 1, Batch Index: 600, Loss: 0.24327732622623444\n",
      "Train Epoch: 1, Batch Index: 800, Loss: 0.09452737867832184\n",
      " Test Accuracy: 97.49%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BSZ = 64\n",
    "LR = 1e-3\n",
    "EPOCH = 1\n",
    "\n",
    "# we need to use DataLoader to pass data to the model\n",
    "# it will yield batches of data\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=BSZ,\n",
    "                                          shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                         batch_size=BSZ)\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "    ## uncomment this line to save the trained model \n",
    "#     torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, I trained for only one epoch.\n",
    "\n",
    "You can try training for more epochs, designing better model structures or use other tricks to further improve the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model so you can load it later\n",
    "SAVE_PATH = \"mnist_cnn.ckpt\"\n",
    "torch.save(model.state_dict(), SAVE_PATH)\n",
    "\n",
    "## load the model \n",
    "model = Net()\n",
    "model.load_state_dict(torch.load(SAVE_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a predict function to do prediction\n",
    "def predict(model, img):\n",
    "    model.eval()\n",
    "    output = model(torch.reshape(img,(1,1,28,28)))\n",
    "    pred = output.argmax(dim=1,)\n",
    "    return pred.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1233aa4e0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Pick a random image from Test Set and see what the model predicts\n",
    "img, lab = test_data[666]\n",
    "print (\"Label:\", lab)\n",
    "\n",
    "img = img.reshape(28, 28)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: 7\n"
     ]
    }
   ],
   "source": [
    "print (\"Model prediction:\", predict(model, img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the index above to compare results for other test images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/pytorch/examples/tree/master/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
